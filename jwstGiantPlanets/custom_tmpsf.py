import os
import warnings
warnings.filterwarnings("ignore")
import numpy as np
#from scipy.interpolate import RegularGridInterpolator, CloughTocher2DInterpolator
from scipy.signal import fftconvolve
from scipy import interpolate

import matplotlib
matplotlib.use('Agg')  # Use non-interactive backend
import matplotlib.pyplot as plt
from matplotlib.colors import LogNorm
import planetmapper
PLANETMAPPER_KW = {}

#from astropy.wcs.utils import proj_plane_pixel_scales
from scipy import ndimage
import os
import astropy.io.fits as apfits
from astropy.wcs import WCS
from astropy.wcs.utils import fit_wcs_from_points
from astropy.coordinates import SkyCoord
import astropy.units as u
from astropy.constants import h, c, k_B

import cv2
import pickle
from tqdm import tqdm



def save_fits_with_planetmapper_backplanes(datafile, body, savefile, offsets=(0,0), basepath=None, overwrite_backplanes=True, add_wcs=False):
    """Convenience function to save a fits file with all existing extensions plus backplanes generated by
    PlanetMapper.
    INPUTS:
        datafile: str or hdul: path to original fits file or hdul fits object
        body: PlanetMapper.Body, BodyXY, or Observation: planetmapper object containing backplanes
        savefile: str: path or relative path to new fits file
        offsets (0,0): tuple(ra_offset, dec_offset): ra and dec offsets in arcseconds
        basepath (None): str: if provided, sets relative basepath for both datafile and savefile paths
        overwrite_backplanes: bool: if True will overwrite existing backplanes otherwise will error if backplanes exist
        add_wcs: bool: if true add WCS keywords relevant to planetmapper body -- note only do this for fake observations (e.g. model),
            otherwise this may cause issues if the observation WCS parameters from the telescope header are overwritten.
    OUTPUT:
        None, writes fits file at basepath+savefile
    """
    def check_extension(hdul, name):
        """Check whether named fits extension already exists."""
        if name.lower() in [hdu.name.lower() for hdu in hdul]:
            return True
        return False

    if basepath: # update savefile to include basepath
        savefile = os.path.join(basepath, savefile) 
    # Create directories if needed
    if not os.path.exists(os.path.join('/', *savefile.split('/')[:-1])):
        os.makedirs(os.path.join('/', *savefile.split('/')[:-1])) 
    
    # Get datafile HDU list
    if type(datafile) == apfits.HDUList:
        hdul = datafile
    elif basepath:
        hdul = apfits.open(os.path.join(basepath, datafile))
    else:
        hdul = apfits.open(datafile)

    # Add backplanes
    for key in body.backplanes.keys():
        if check_extension(hdul, key):
            if overwrite_backplanes is False:
                print("Backplane ",key,' already exists and overwrite_backplanes is False, so no files were saved.')
                return
            else:
                hdul.pop(key) # remove current fits extension assoicated with backplane

        # Add backplane
        data = body.get_backplane_img(key)
        hdr = apfits.Header()
        hdr.add_comment(f'Backplane generated by PlanetMapper.{body.__class__.__name__}')
        hdr.add_comment(body.backplanes[key].description)
        hdu = apfits.ImageHDU(data=data, header=hdr, name=key)
        hdul.append(hdu)
    
    if hasattr(hdul[0].header, 'HIERARCH NAV RA_OFFSET'):
        hdul[0].header['HIERARCH NAV RA_OFFSET'] = hdul[0].header['HIERARCH NAV RA_OFFSET'] + offsets[0]
    else:
        hdul[0].header['HIERARCH NAV RA_OFFSET'] = offsets[0]
    if hasattr(hdul[0].header, 'HIERARCH NAV DEC_OFFSET'):
        hdul[0].header['HIERARCH NAV DEC_OFFSET'] = hdul[0].header['HIERARCH NAV DEC_OFFSET'] + offsets[1]
    else:
        hdul[0].header['HIERARCH NAV DEC_OFFSET'] = offsets[1]
    
    if add_wcs:
        print('The add_wcs section of this function is not currently working as expected, so no WCS info was added to the saved fits file.')
        # Note: for now this allows overwriting of telescope WCS info but should not be used for that purpose.
        # To Do: maybe produce error or warning if overwriting existing WCS instead of adding fake WCS?
    hdul.writeto(savefile, overwrite=True)

# from scipy.interpolate import CloughTocher2DInterpolator
# def nanaware_shift(data, xshift, yshift, xscale=1, yscale=1):
#     """
#     Shift a 2D array with NaNs using interpolation.

#     Parameters:
#         data : 2D numpy array with NaNs
#         xshift, yshift : float (subpixel shift in pixels)
#         xscale, yscale : float: scaling factor in x and y directions
#             Note this may mess with values at the edges.

#     Returns:
#         shifted array (same shape), with NaNs preserved
#     """
#     #xshift, yshift = xshift*xscale, yshift*yscale
#     X,Y = np.meshgrid(np.arange(data.shape[0]), np.arange(data.shape[1]), indexing='ij')
#     points = np.column_stack((X.ravel(),  Y.ravel()))
#     data_flat = data.ravel()
#     # Remove nans for interpolator
#     valid_mask = ~np.isnan(data_flat)
#     valid_points = points[valid_mask]
#     valid_data = data_flat[valid_mask]
#     fdata = CloughTocher2DInterpolator(valid_points, valid_data, fill_value=np.nan)

#     # Build grid of output coordinates, shifted
#     newpoints = np.column_stack(((xscale*(X-xshift)).ravel(),  (yscale*(Y-yshift)).ravel()))
#     shifted = fdata(newpoints).reshape(data.shape)

#     return shifted

def create_oversampled_wcs(obs_wcs, model_shape, newpixsc=5, sample_step = 10):
    """
    Create a WCS object for an oversampled model using astropy's fit_wcs_from_points.
    This approach creates a grid of RA/DEC values at model pixel locations
    by extrapolating from the observation, then fits a proper WCS.
    
    Parameters:
    -----------
    obs_wcs : astropy.wcs.WCS
        The WCS object from the original observation
    model_shape : tuple
        Shape of the model array (nwave, ny, nx) or (ny, nx)
    newpixsc : float
        Oversampling factor (pixel scale reduction factor)
    
    Returns:
    --------
    model_wcs : astropy.wcs.WCS
        WCS object for the oversampled model
    """
    if len(model_shape) == 2:
        ny_model, nx_model = model_shape
        nwave = None
    elif len(model_shape) == 3:
        nwave, ny_model, nx_model = model_shape

    if nwave is None:
        # Get points throughout image to pull RA/DEC
        X, Y = np.meshgrid(np.arange(0, nx_model, sample_step), np.arange(0, ny_model, sample_step))
        
        # Handle both 2D and 3D WCS
        if obs_wcs.naxis == 3:
            # For 3D WCS, need to provide z coordinate (use 0 for wavelength/spectral axis)
            radec = obs_wcs.wcs_pix2world(X/newpixsc, Y/newpixsc, 0, 0)
        else:
            # For 2D WCS
            radec = obs_wcs.wcs_pix2world(X/newpixsc, Y/newpixsc, 0)
            
        coords = SkyCoord(radec[0]*u.deg, radec[1]*u.deg)

        # Fit WCS to points
        model_wcs = fit_wcs_from_points((X.flatten(),Y.flatten()), coords.flatten(), sip_degree=3)
        return model_wcs
    else:
        print('Not currently working for 3D wcs yet :()')
        return
    
# Verify the transformation works correctly
def verify_wcs_consistency(obs_wcs, model_wcs, newpixsc, obs_shape=None, model_shape=None):
    """
    Verify that the same sky position maps correctly between observation and model
    at multiple test points including center, corners, and disk edges
    """
    print("=== WCS CONSISTENCY VERIFICATION ===")
    
    # Get observation dimensions
    if obs_shape is None:
        obs_ny, obs_nx = int(obs_wcs.array_shape[-2]), int(obs_wcs.array_shape[-1])
    else:
        obs_ny, obs_nx = obs_shape[-2], obs_shape[-1]
    
    # Test points: center, corners, and disk edge points
    test_points = [
        # Center
        (obs_nx//2, obs_ny//2, "Center"),
        # Corners
        (0, 0, "Top-left corner"),
        (obs_nx-1, 0, "Top-right corner"), 
        (0, obs_ny-1, "Bottom-left corner"),
        (obs_nx-1, obs_ny-1, "Bottom-right corner"),
        # Edge midpoints
        (obs_nx//2, 0, "Top edge"),
        (obs_nx//2, obs_ny-1, "Bottom edge"),
        (0, obs_ny//2, "Left edge"),
        (obs_nx-1, obs_ny//2, "Right edge"),
    ]
    
    max_error = 0
    all_consistent = True
    
    for obs_x, obs_y, label in test_points:
        # Convert observation pixel to sky coordinates
        if obs_wcs.naxis == 3:
            sky_coord = obs_wcs.pixel_to_world(obs_x, obs_y, 0)
            ra, dec = sky_coord[0].ra.deg, sky_coord[0].dec.deg
        else:
            sky_coord = obs_wcs.pixel_to_world(obs_x, obs_y)
            ra, dec = sky_coord.ra.deg, sky_coord.dec.deg
        
        # Convert the same sky coordinates back to model pixels
        if model_wcs.naxis == 3:
            model_pix = model_wcs.world_to_pixel_values(ra, dec, model_wcs.wcs.crval[2])
            model_x, model_y = model_pix[0], model_pix[1]
        else:
            model_pix = model_wcs.world_to_pixel_values(ra, dec)
            model_x, model_y = model_pix[0], model_pix[1]
        
        # Expected model pixel position
        expected_model_x, expected_model_y = obs_x * newpixsc, obs_y * newpixsc
        
        # Calculate errors
        error_x = abs(model_x - expected_model_x)
        error_y = abs(model_y - expected_model_y)
        total_error = (error_x**2 + error_y**2)**0.5
        max_error = max(max_error, total_error)
        
        # Check if consistent (within 2 pixels)
        is_consistent = error_x < 2.0 and error_y < 2.0
        all_consistent = all_consistent and is_consistent
        
        status = "✓" if is_consistent else "✗"
        print(f"{status} {label}: obs({obs_x:.1f},{obs_y:.1f}) -> sky({ra:.6f},{dec:.6f}) -> model({model_x:.1f},{model_y:.1f}) [expected({expected_model_x:.1f},{expected_model_y:.1f})] error={total_error:.2f}px")
    
    print(f"Maximum pixel error: {max_error:.2f}")
    print(f"Overall consistency: {'PASS' if all_consistent else 'FAIL'}")

### Functions to smooth weird disk edge effects in the produced models ###  
from scipy import ndimage
def find_edge_pixels(valid_mask, edge_width):
    """Find pixels within edge_width of the disk boundary."""
    # Erode the valid mask to find interior pixels
    structure = ndimage.generate_binary_structure(2, 2)  # 8-connected
    eroded = valid_mask.copy()
    
    # Erode multiple times to get the desired edge width
    for _ in range(edge_width):
        eroded = ndimage.binary_erosion(eroded, structure)
    
    # Edge pixels are valid pixels that are not in the eroded interior
    edge_mask = valid_mask & ~eroded
    return edge_mask

def gaussian_edge_smoothing(data, edge_mask, sigma=1.0):
    """Apply Gaussian smoothing only to edge pixels."""
    smoothed = data.copy()
    valid_mask = ~np.isnan(smoothed)

    # Create a version with NaN replaced by interpolated values for smoothing
    temp_data = data.copy()
    temp_data[~valid_mask] = 0  # Replace NaN with 0 for filtering
    
    # Apply Gaussian filter
    filtered = ndimage.gaussian_filter(temp_data, sigma=sigma)
    
    # Also filter the mask to get proper normalization
    mask_filtered = ndimage.gaussian_filter(valid_mask.astype(float), sigma=sigma)
    
    # Normalize the filtered result
    with np.errstate(divide='ignore', invalid='ignore'):
        normalized_filtered = filtered / mask_filtered
        normalized_filtered[mask_filtered == 0] = 0
    
    # Replace edge pixels with smoothed values
    smoothed[edge_mask] = normalized_filtered[edge_mask]
    return smoothed

def create_disk_mask(shape, center_x, center_y, radius):
    """Create a boolean mask for pixels within the disk."""
    i_coords, j_coords = np.ogrid[:shape[0], :shape[1]]
    distances = np.sqrt((j_coords - center_x)**2 + (i_coords - center_y)**2)
    return distances <= radius

from scipy.interpolate import griddata
def inpaint_disk_nans(data, center_x, center_y, radius, method='biharmonic'):
    """
    Advanced inpainting method using scipy's interpolation.
    Requires scipy.ndimage for more sophisticated filling.
    """
    
    filled = data.copy()
    
    # Create disk mask
    disk_mask = create_disk_mask(data.shape, center_x, center_y, radius)
    
    # Find valid and NaN pixels within disk
    valid_in_disk = ~np.isnan(data) & disk_mask
    nan_in_disk = np.isnan(data) & disk_mask
    
    if not np.any(nan_in_disk):
        return filled
    
    # Get coordinates and values of valid pixels
    valid_coords = np.where(valid_in_disk)
    valid_points = np.column_stack((valid_coords[1], valid_coords[0]))  # (x, y) format
    valid_values = data[valid_in_disk]
    
    # Get coordinates of NaN pixels to fill
    nan_coords = np.where(nan_in_disk)
    nan_points = np.column_stack((nan_coords[1], nan_coords[0]))  # (x, y) format
    
    # Interpolate using griddata
    if method == 'linear':
        interpolated = griddata(valid_points, valid_values, nan_points, method='linear')
    elif method == 'cubic':
        interpolated = griddata(valid_points, valid_values, nan_points, method='cubic')
    else:  # nearest neighbor fallback
        interpolated = griddata(valid_points, valid_values, nan_points, method='nearest')
    
    # Fill the NaN pixels
    filled[nan_in_disk] = interpolated
    
    return filled

### Thermal model functions ###
def planck_lambda(wavelength, temperature, emissivity=1.0):
    """
    Compute spectral radiance B_lambda in W / (m² µm sr)
    wavelength: astropy Quantity with length units (e.g. micron, m)
    temperature: astropy Quantity with temperature units (e.g. K)
    """
    # Ensure proper units
    wavelength = wavelength.to(u.m)
    temperature = temperature.to(u.K)

    # If emissivity is not 1, convert to brightness temperature
    # if emissivity < 1.0:
    #     temperature = emissivity * temperature

    # Compute exponent (must be dimensionless)
    exponent = (h * c) / (wavelength * k_B * temperature)
    exponent_val = exponent.to_value(u.dimensionless_unscaled)

    # Compute numerator and denominator separately
    numerator = (2 * h * c**2) / wavelength**5
    denominator = (np.exp(exponent_val) - 1)*u.sr  # use expm1 for stability

    # Final result: B_lambda
    B_lambda = numerator / denominator  # units: W / (m² m sr)

    return emissivity * B_lambda.to(u.W / (u.m**2 * u.um * u.sr))  # Convert to W/m²/µm/sr

def planck_flux_density(wavelength, temperature, omega_pix, emissivity=1.0, outunit='uJy'):
    """
    Compute spectral radiance B_lambda and convert to flux density (uJy per pixel) given a 
    pixel solid angle omega_pix in steradians.
    
    wavelength: astropy Quantity with length units (e.g. micron, m)
    temperature: astropy Quantity with temperature units (e.g. K)
    omega_pix: astropy Quantity with solid angle units (e.g. sr)
    emissivity: float: emissivity of the surface (default 1.0)
    outunit: str: valid astropy flux unit string (default 'uJy'), could do e.g. 'MJy' or 'Jy'
    """
    B_lambda = planck_lambda(wavelength, temperature, emissivity)
    
    B_nu = (B_lambda * (wavelength.to(u.m)**2/c)).to(u.W/(u.m**2*u.Hz*u.sr))
    return (B_nu * omega_pix).to(outunit)  

def get_model_bb_image(waves, temps, omega_pix, emissivity=1.0, outunit='uJy'):
    """
    Generate a model black body image from a list of wavelengths and temperatures.
    
    Parameters:
    -----------
    waves : astropy Quantity array
        Wavelengths in microns or meters
    temps : astropy Quantity array, can be 2D for extended object image
        Temperatures in Kelvin
    omega_pix : astropy Quantity
        Solid angle per pixel in steradians
    emissivity : float
        Emissivity of the surface (default 1.0)
    outunit : str
        Output unit for flux density (default 'uJy')
    
    Returns:
    --------
    model_image : 3D array
        Image with flux density values in specified units
    """
    
    return np.array([planck_flux_density(wl, temps, omega_pix) for wl in waves]) 

def bin_image(img, factor):
    """Bin image by summing non-overlapping NxN blocks"""
    shape = (img.shape[0]//factor, factor, img.shape[1]//factor, factor)
    return img.reshape(shape).sum(-1).sum(1)

def find_percent_flux_radius(flux_cube, center_x, center_y, min_radius=0, max_radius=None, radius_step=0.1, flux_frac=0.99):
    """
    Find the radius at each wavelength where flux_frac% of the total flux is captured.
    
    Parameters:
    -----------
    flux_cube : numpy.ndarray
        3D array with shape (n_wavelengths, n_y, n_x) containing flux values
    center_x : float
        X-coordinate of disk center (in pixel coordinates)
    center_y : float  
        Y-coordinate of disk center (in pixel coordinates)
    min_radius : float, optional 
        Minimum radius to search (default: 0 pixels)
    max_radius : float, optional
        Maximum radius to search. If None, uses half the minimum image dimension
    radius_step : float, optional
        Step size for radius sampling (default: 0.1 pixels)
    flux_frac: float, optional
        Fraction of total flux to capture (default: 0.99 for 99%)
        
    Returns:
    --------
    radii_frac : numpy.ndarray
        Array of radii (in pixels) where flux_frac% of flux is captured for each wavelength
    flux_fractions : numpy.ndarray
        2D array of cumulative flux fractions vs radius for each wavelength
    radius_array : numpy.ndarray
        Array of radius values used for sampling
    """

    n_wvs, n_y, n_x = flux_cube.shape
    # Set maximum radius if not provided
    if max_radius is None:
        max_radius = min(n_x, n_y) / 2.0

    # Create coordinate grids
    y_coords, x_coords = np.ogrid[:n_y, :n_x]
    # Calculate distance from center for each pixel
    distances = np.sqrt((x_coords - center_x)**2 + (y_coords - center_y)**2)
    # Create radius sampling array
    radius_array = np.arange(min_radius, max_radius + radius_step, radius_step)
    n_radii = len(radius_array)

    # Initialize output arrays
    radii_frac = np.zeros(n_wvs)
    flux_fractions = np.zeros((n_wvs, n_radii))

    # Process each wavelength
    for wave_idx in range(n_wvs):
        flux_2d = flux_cube[wave_idx,:,:]
        # Calculate total flux for this wavelength
        total_flux = np.nansum(flux_cube[wave_idx,:,:])

        # Calculate cumulative flux as function of radius
        cumulative_flux = np.zeros(n_radii)

        for r_idx, radius in enumerate(radius_array):
            # Create circular aperture mask
            mask = distances <= radius
            
            # Sum flux within aperture
            cumulative_flux[r_idx] = np.sum(flux_2d[mask])

        # Convert to flux fractions
        flux_fractions[wave_idx, :] = cumulative_flux / total_flux

        # Find radius where specified % of flux is captured
        # Use interpolation for sub-pixel precision
        if flux_fractions[wave_idx, -1] >= flux_frac:
            # Find the crossing point
            interp_func = interpolate.interp1d(flux_fractions[wave_idx, :], radius_array, 
                                                kind='linear', bounds_error=False, 
                                                fill_value=(radius_array[0], radius_array[-1]))
            radii_frac[wave_idx] = interp_func(flux_frac)
        else:
            # flux_frac not reached within max_radius
            radii_frac[wave_idx] = np.nan
            print(f"Warning: {flux_frac*100}% flux not captured within max_radius for wavelength index {wave_idx}")

    return radii_frac, flux_fractions, radius_array


### Main function to run the thermal + psf model production step ###

def generate_thermal_models(datapath, path_pattern='bg_fringe_fringe1d',
                                thermal_info = {'obskey_prefix': '',
                                                'target': 'Callisto',
                                                'inertias': [10, 30, 50, 100, 200]}):
    """
    Generate oversampled thermal models for MIRI Callisto observations and convolve
    with MIRI psf at each wavelength slice to produce model observation.
    This function crops the observations, creates oversampled WCS, and generates
    an oversampled thermal model (temperature map) for each observation and saves
    the results.
    
    Parameters:
    -----------
    datapath : dict
        Dictionary with keys for hemisphere e.g. 'lead' and 'trail' pointing to data directories
    path_pattern : str ('bg_fringe_fringe1d')
        Pattern for data dictionary produced by jwstGiantPlanets pipeline
    thermal_info: dict
        Dictionary with keys:
            'obskey_prefix': str, prefix for observation keys (e.g. 'g' for Ganymede)
            'target': str, target name for thermal models (e.g. 'Callisto')
            'inertias': list of int, thermal inertia values to process
    
    Returns:
    --------
    None
    """

    for hem in datapath.keys():
        for dith in ['d1', 'd2', 'd3', 'd4']:
            if not os.path.exists(f"{datapath[hem]}/{dith}_{path_pattern}_cropped/plots/"):
                os.makedirs(f"{datapath[hem]}/{dith}_{path_pattern}_cropped/plots/")
            for ch in ['1', '2', '3', '4']:
                for band in ['SHORT', 'MEDIUM', 'LONG']:

                    # Get rotation from the actual miri data
                    filenm = f"{datapath[hem]}/{dith}_{path_pattern}/Level3_ch{ch}-{band.lower()}_s3d_nav.fits"
                    body = planetmapper.Observation(
                            filenm, aberration_correction='CN', **PLANETMAPPER_KW
                            )
                    #body.fit_disc_position() # Take manually corrected position (hopefully this works??)
                    rotation = body.get_rotation()
                    utc = body.utc
                    print(f'Loaded Observation {hem} {dith} ch{ch}-{band.lower()}...')

                    ### -- Crop both the observation and thermal model -- ###

                    # Crop observation fits image and save
                    cropped_filenm = f"{datapath[hem]}/{dith}_{path_pattern}_cropped/Level3_ch{ch}-{band.lower()}_s3d_nav_cropped.fits"
                    if not os.path.exists(os.path.join('/', *cropped_filenm.split('/')[:-1])):
                        os.makedirs(os.path.join('/', *cropped_filenm.split('/')[:-1])) 

                    x,y,r = body.get_x0(), body.get_y0(), body.get_r0()
                    npix = 5 # number of extra pixels to keep
                    minx, maxx = int(np.floor(x-r-npix)), int(np.ceil(x+r+npix))+1
                    miny, maxy = int(np.floor(y-r-npix)), int(np.ceil(y+r+npix))+1

                    hdul = apfits.open(filenm, memmap=False)
                    target_ra = hdul[0].header['TARG_RA']
                    target_dec = hdul[0].header['TARG_DEC']
                    # Update WCS for the cropped image and ra/dec shift to target
                    w = WCS(hdul[1].header)
                    # shift to account for cropping
                    w.wcs.crpix[0] -= minx  # X axis
                    w.wcs.crpix[1] -= miny  # Y axis
                    # Apply offset to CRVAL to force (x0, y0) → target RA/DEC
                    x0, y0 = body.get_x0(), body.get_y0()
                    
                    # Handle both 2D and 3D WCS
                    if w.naxis == 3:
                        # For 3D WCS, need to provide z coordinate (use 0 for wavelength/spectral axis)
                        current_ra, current_dec = w.wcs_pix2world(x0-minx, y0-miny, 0, 0)[:2]
                    else:
                        # For 2D WCS
                        current_ra, current_dec = w.wcs_pix2world(x0-minx, y0-miny, 0)[:2]
                    dra, ddec = current_ra - target_ra, current_dec-target_dec
                    w.wcs.crval[0] += dra - hdul[0].header['HIERARCH NAV RA_OFFSET']/3600
                    w.wcs.crval[1] += ddec - hdul[0].header['HIERARCH NAV DEC_OFFSET']/3600

                    #update wcs info in header
                    wcshdr = w.to_header()
                    for key in wcshdr.keys():
                        hdul[1].header[key] = wcshdr[key]

                    for hdu in hdul:
                        if hdu.data is not None:
                            if hdu.name == 'RA':
                                hdu.data = hdu.data[miny:maxy,minx:maxx]+dra
                            elif hdu.name == 'DEC':
                                hdu.data = hdu.data[miny:maxy,minx:maxx]+ddec
                            elif len(hdu.data.shape) == 3:
                                hdu.data = hdu.data[:,miny:maxy,minx:maxx]
                            elif len(hdu.data.shape) == 2:
                                hdu.data = hdu.data[miny:maxy,minx:maxx]
                    hdul[0].header['HIERARCH CROP NPIX'] = npix
                    hdul[0].header['HIERARCH CROP MINX'] = minx
                    hdul[0].header['HIERARCH CROP MAXX'] = maxx
                    hdul[0].header['HIERARCH CROP MINY'] = miny
                    hdul[0].header['HIERARCH CROP MAXY'] = maxy
                    hdul[0].header['HIERARCH NAV RA_OFFSET'] = 0
                    hdul[0].header['HIERARCH NAV DEC_OFFSET'] = 0
                    hdul[0].header['PLANMAP DISC X0'] = hdul[0].header['PLANMAP DISC X0'] - minx
                    hdul[0].header['PLANMAP DISC Y0'] = hdul[0].header['PLANMAP DISC Y0'] - miny
                    hdul.writeto(cropped_filenm, overwrite=True)

                    # Resave fits file with final backplanes
                    body = planetmapper.Observation(cropped_filenm)
                    # save_fits_with_planetmapper_backplanes(cropped_filenm, body, cropped_filenm)
                    print(f'Cropped observation and saved to {cropped_filenm}')

                    ### -- Resample model temps and crop to match observation but oversampled by 5 -- ###

                    newpixsc = 5 # 5 model pixels for every observed pixel
                    obskey = f"{thermal_info['obskey_prefix']}{hem[0].upper()}{dith[1]}{ch}{band[0].lower()}"
                    with apfits.open(cropped_filenm) as hdul:
                        obs_data = np.nanmedian(hdul['SCI'].data, axis=0)
                        obs_wcs = WCS(hdul[1].header)
                        ny, nx = obs_data.shape[-2:]

                    # Create oversampled WCS
                    body = planetmapper.Observation(cropped_filenm)
                    obsr = body.get_r0() # observation radius for scaling
                    obsx, obsy = body.get_x0(), body.get_y0()

                    print('Creating oversampled WCS for thermal models...')
                    new_nx = nx * newpixsc
                    new_ny = ny * newpixsc
                    new_shape = (new_ny, new_nx) #(1, new_ny, new_nx)
                    # Create a new WCS with the same projection but oversampled
                    new_wcs = create_oversampled_wcs(w, new_shape, newpixsc)

                    

                    for inertia in thermal_info['inertias']: # Need to apply same scaling and wcs to all thermal models (assuming they were created on identical grids)
                        # Load thermal model and scale
                        print(f'Scaling thermal model for TI={inertia}...')
                        temppath = f"/home/rdavis/DataAnalysis/pipelines/thermalmodel/obsmodels/{thermal_info['target']}MIRI/{obskey}/{obskey}_mapped_temps_TI_{inertia}.fits"
                        tm = planetmapper.Observation(temppath, target=thermal_info['target'], utc=utc)
                        tm.fit_disc_position()
                        tm.fit_disc_radius()
                        # tm.set_rotation(rotation) # pretty sure rotation of the model is 0...
                        x,y,r,rot = tm.get_disc_params()
                        with apfits.open(temppath) as hdul:
                            temps = hdul[0].data
                            minT = np.nanmin(temps[temps!=0])
                        temps = ndimage.zoom(temps, (newpixsc*obsr)/r)
                        newx, newy = x*(newpixsc*obsr)/r, y*(newpixsc*obsr)/r
                        newr = newpixsc*obsr
                        dx,dy = (obsx*newpixsc - newx)%1, (obsy*newpixsc - newy)%1
                        temps = ndimage.shift(temps, shift=(dx,dy))
                        newx, newy = newx+dx, newy+dy
                        xx,yy = np.meshgrid(np.arange(temps.shape[0]), np.arange(temps.shape[1]))
                        mask = np.sqrt((xx-newx)**2 + (yy-newy)**2) > newr
                        temps[mask] = np.nan
                        temps[temps<minT] = np.nan

                        ## Insert into correct model size and apply subpixel shift to exactly match observation
                        model_data = np.full((new_ny, new_nx), np.nan)
                        insert_x, insert_y = int(newpixsc*obsx - newx), int(newpixsc*obsy - newy) # if i did the shift right these should be integers
                        try:
                            model_data[
                                insert_y:insert_y + temps.shape[0],
                                insert_x:insert_x + temps.shape[1]
                            ] = temps
                        except ValueError:
                            max_x, max_y = insert_x + temps.shape[1], insert_y + temps.shape[0]
                            if max_y > model_data.shape[0]:
                                max_y = model_data.shape[0]
                                temps = temps[:max_y-insert_y ,:]
                            if max_x > model_data.shape[1]:
                                max_x = model_data.shape[1]
                                temps = temps[:,:max_x-insert_x]
                            model_data[
                                insert_y:max_y,
                                insert_x:max_x
                            ] = temps

                        # rotate model to match observation orientation
                        center = (model_data.shape[0]//2, model_data.shape[1]//2)
                        model_data = cv2.warpAffine(model_data, cv2.getRotationMatrix2D(center, rotation, 1.0), (model_data.shape[0], model_data.shape[1]))

                        ### -- Write model and oversampled WCS info to disk -- ###
                        # Add observation header and update
                        with apfits.open(cropped_filenm) as hdul:
                            hdr = hdul[1].header
                        hdr['WCSAXES'] = 3
                        hdr['NAXIS1'] = new_nx
                        hdr['NAXIS2'] = new_ny
                        hdr['NAXIS3'] = 1
                        # Add new wcs keys:
                        wcshdr = new_wcs.to_header()
                        for key in wcshdr.keys():
                            hdr[key] = wcshdr[key]
                        hdu_model = apfits.ImageHDU(data=model_data[None,:,:], header=hdr)
                        hdu_model.name = 'SCI'  # name of the science extension (PlanetMapper expects this)
                        #Add primary header with observation info
                        with apfits.open(cropped_filenm) as hdul:
                            obshdr = hdul[0].header
                        with apfits.open(temppath) as hdul:
                            primary_hdr = hdul[0].header
                        primary_hdr['SIMPLE'] = 'T'
                        primary_hdr['EXTEND'] = 'T'
                        primary_hdr['EXTNAME'] = 'PRIMARY'
                        primary_hdr['TARGNAME'] = obshdr['TARGNAME']
                        primary_hdr['MODEL_TI'] = inertia #record model thermal inertia
                        primary_hdr['TARG_RA'] = target_ra
                        primary_hdr['TARG_DEC'] = target_dec
                        primary_hdr['DATE-OBS'] = obshdr['DATE-OBS']
                        primary_hdr['TIME-OBS'] = obshdr['TIME-OBS']
                        primary_hdr['EXPMID'] = obshdr['EXPMID']
                        primary_hdr['TARGTYPE'] = obshdr['TARGTYPE']
                        primary_hdr['VISITYPE'] = obshdr['VISITYPE']
                        primary_hdr['S_MTWCS'] = obshdr['S_MTWCS']
                        primary_hdr['VA_RA'] = obshdr['VA_RA']
                        primary_hdr['VA_DEC'] = obshdr['VA_DEC']
                        primary_hdr['TELESCOP'] = obshdr['TELESCOP']
                        primary_hdr['INSTRUME'] = obshdr['INSTRUME']
                        primary_hdr['DETECTOR'] = obshdr['DETECTOR']
                        primary_hdr['CHANNEL'] = obshdr['CHANNEL']
                        primary_hdr['BAND'] = obshdr['BAND']
                        primary_hdr['HIERARCH NAV RA_OFFSET'] = 0.0
                        primary_hdr['HIERARCH NAV DEC_OFFSET'] = 0.0
                        primary_hdr['HIERARCH PLANMAP DISC X0'] = obsx*newpixsc
                        primary_hdr['HIERARCH PLANMAP DISC Y0'] = obsy*newpixsc
                        primary_hdr['HIERARCH PLANMAP DISC R0'] = obsr*newpixsc
                        primary_hdr['HIERARCH PLANMAP DISC ROT'] = rot
                        # Create primary hdu with header
                        hdu_primary = apfits.PrimaryHDU(header=primary_hdr)
                        # Write to file
                        hdul_out = apfits.HDUList([hdu_primary, hdu_model])
                        savetemp =  f"{datapath[hem]}/{dith}_{path_pattern}_cropped/Level3_ch{ch}-{band.lower()}_resampled_model_temps_TI_{inertia}.fits"
                        hdul_out.writeto(savetemp, overwrite=True, output_verify='fix')

                        ## Fix weird edge effects
                        modelfilenm =  savetemp
                        tmbody = planetmapper.Observation(modelfilenm)
                        x,y,r = tmbody.get_x0(), tmbody.get_y0(), tmbody.get_r0()
                        
                        hdul = apfits.open(modelfilenm)
                        model_temps = hdul['SCI'].data[0]

                        new_temps = gaussian_edge_smoothing(model_temps, find_edge_pixels(~np.isnan(model_temps), 2), sigma=1.5)
                        new_temps = inpaint_disk_nans(new_temps, x, y, r)
                        new_temps[~create_disk_mask(new_temps.shape, x, y, r)] = np.nan

                        hdul['SCI'].data[0] = new_temps
                        hdul.writeto(modelfilenm, overwrite=True)

                        tmbody = planetmapper.Observation(savetemp)
                        save_fits_with_planetmapper_backplanes(savetemp, tmbody, savetemp)
                        print(f'Saved resampled thermal model to {savetemp}')

                        # Save plot
                        fig, ax = plt.subplots(1,2, figsize=(10,5), width_ratios=[1,1.2])
                        m1 = ax[0].pcolormesh(
                                        body.get_ra_img(),
                                        body.get_dec_img(),
                                        np.nanmedian(body.data,axis=0),
                                        cmap='plasma')
                        # plt.colorbar(m1, ax=ax[0])
                        body.plot_wireframe_radec(ax[0])

                        m2 = ax[1].pcolormesh(
                                        tmbody.get_ra_img(),
                                        tmbody.get_dec_img(),
                                        tmbody.data[0], cmap='plasma')
                        plt.colorbar(m2, ax=ax[1])
                        tmbody.plot_wireframe_radec(ax[1])

                        moon = thermal_info['target']
                        moon_ids = {'callisto': 504, 'ganymede': 503, 'europa': 502}
                        targid = moon_ids.get(moon.lower())
                        ax[0].set_title(ax[0].get_title().split(moon.upper())[1].replace(f' ({targid})', '{moon} Observation '+str(obskey)).replace('from JAMES WEBB SPACE TELESCOPE', f"from JWST"))
                        ax[1].set_title(ax[1].get_title().split(moon.upper())[1].replace(f' ({targid})', f'Thermal Model for TI={inertia}').replace('from JAMES WEBB SPACE TELESCOPE', f"for {obskey} from JWST"))
                        plot_filename = f"{datapath[hem]}/{dith}_{path_pattern}_cropped/plots/comparison_plot_{obskey}_TI_{inertia}.png"
                        print(f'Saving plot to {plot_filename}')
                        plt.savefig(plot_filename, dpi=150, bbox_inches='tight')

def generate_thermal_psf_models(datapath, path_pattern='bg_fringe_fringe1d',
                                thermal_info = {'obskey_prefix': '',
                                                'target': 'Callisto',
                                                'inertias': [10, 30, 50, 100, 200]},
                                psf_kernel_path = f"/home/rdavis/DataAnalysis/pipelines/MIRISatellites/jwstGiantPlanets/miri_psf_kernels.pkl"):
    """
    Convolve oversampled thermal models for MIRI galsat observations
    with MIRI psf at each wavelength slice to produce model observation.
    Rescales the thermal models, creates the thermal+psf model, resamples it to match 
    the observation, and saves the results.
    
    Parameters:
    -----------
    datapath : dict
        Dictionary with keys for hemisphere e.g. 'lead' and 'trail' pointing to data directories
    path_pattern : str ('bg_fringe_fringe1d')
        Pattern for data dictionary produced by jwstGiantPlanets pipeline
    thermal_info: dict
        Dictionary with keys:
            'obskey_prefix': str, prefix for observation keys (e.g. 'g' for Ganymede)
            'target': str, target name for thermal models (e.g. 'Callisto')
            'inertias': list of int, thermal inertia values to process
    psf_kernel_path: str: path to pickled stpsfs dictionary with PSF kernels
    
    Returns:
    --------
    None
    """
    with open(psf_kernel_path, 'rb') as f:
        psf_kernels = pickle.load(f)

    total_iterations = len(datapath.keys()) * len(['d1', 'd2', 'd3', 'd4']) * len(['1', '2', '3', '4']) * len(['SHORT', 'MEDIUM', 'LONG'])
    with tqdm(total=total_iterations, desc="Processing") as pbar:
        for hem in datapath.keys():
            for dith in ['d1', 'd2', 'd3', 'd4']:
                for ch in ['1', '2', '3', '4']:
                    for band in ['SHORT', 'MEDIUM', 'LONG']:
                        obsfilenm = f"{datapath[hem]}/{dith}_{path_pattern}_cropped/Level3_ch{ch}-{band.lower()}_s3d_nav_cropped.fits"
                        body = planetmapper.Observation(obsfilenm)
                        pixel_scale_obs = body.get_plate_scale_arcsec() * u.arcsec  # example: 0.11 arcsec/pixel
                        omega_pix_obs = ((pixel_scale_obs.to(u.rad))**2).to(u.sr)

                        waves = body.get_wavelengths_from_header()*u.m # in m
                        if min(waves.value) > 4: # sometimes it comes back in um ... probably depending on if wcs is 2d or 3d... debug this later
                            waves = waves/1e6
                        waves = waves.to(u.um)
                        
                        # Get psf at each wavelength slice
                        psf_cube_data = psf_kernels[f'({ch},{band})']
                        for inertia in thermal_info['inertias']:
                            # Get thermal model associated with provided inertia
                            modelfilenm =  f"{datapath[hem]}/{dith}_{path_pattern}_cropped/Level3_ch{ch}-{band.lower()}_resampled_model_temps_TI_{inertia}.fits"
                            tmbody = planetmapper.Observation(modelfilenm)
                            model_temps = tmbody.data[0].T

                            pixel_scale = tmbody.get_plate_scale_arcsec() * u.arcsec  # example: 0.11 arcsec/pixel
                            omega_pix = ((pixel_scale.to(u.rad))**2).to(u.sr)
                            flux_cube = get_model_bb_image(waves, model_temps*u.K, omega_pix) # uJy per pixel
                            flux_cube = np.nan_to_num(flux_cube, nan=0)

                            # Convlove flux cube with PSF to simulate observation
                            sim_obs_cube = np.array([
                                fftconvolve(flux_cube[i], psf_cube_data[i]/psf_cube_data[i].sum(), mode='same')
                                for i in range(len(waves))
                            ])
                            # sim_obs_cube[sim_obs_cube<=1e-1] = 1e-1

                            # Now bin to match real observation
                            sim_obs_binned = np.array([
                                bin_image(sim_obs_cube[i], factor=5)
                                for i in range(len(waves))
                            ])

                            flux_rads, flux_fracs, radius_array = find_percent_flux_radius(
                                sim_obs_binned,  body.get_x0(), body.get_y0(), min_radius=body.get_r0(), flux_frac=0.95
                                ) 
                            
                            #Create directories to save models, plots, and observation with attached models
                            savedir = f"{datapath[hem].replace('_desaturated', '_psf')}/{dith}/TI_{inertia}/"
                            if not os.path.exists(savedir):
                                os.makedirs(f"{savedir}/thermal_models/")
                                os.makedirs(f"{savedir}/plots/")
                            
                            ### Add oversampled model flux and PSF convolved model flux to model fits file
                            mod_hdul = apfits.open(modelfilenm)
                            newhdu = apfits.ImageHDU(data=flux_cube, name="BB_FLUX")
                            newhdu.header['BUNIT'] = 'uJy' 
                            newhdu.header['TI'] = inertia
                            newhdu.header.add_comment('Black body flux from model temperatures in uJy per pixel')
                            mod_hdul.append(newhdu)

                            newhdu = apfits.ImageHDU(data=sim_obs_cube, name="MODEL_FLUX")
                            newhdu.header['BUNIT'] = 'uJy' 
                            newhdu.header['TI'] = inertia
                            newhdu.header.add_comment('BB flux from model temperatures in uJy per pixel, convolved with PSF')
                            mod_hdul.append(newhdu)
                            
                            mod_hdul.writeto(f"{savedir}/thermal_models/Level3_ch{ch}-{band.lower()}_resampled_model_temps_TI_{inertia}_psf.fits", overwrite=True)
                            
                            ### Add binned and psf convolved model fluxes to observation fits file + info on aperture radii
                            
                            # Open observation fits file to add models
                            obs_hdul = apfits.open(obsfilenm)
                            # Add the observed flux in uJy as a new HDU -- this is to allow direct comparison with the model flux
                            newhdu = apfits.ImageHDU(data=(obs_hdul['SCI'].data*(u.MJy/u.sr)*omega_pix_obs).to(u.uJy).value, 
                                                    name="OBSERVED_FLUX")
                            newhdu.header['BUNIT'] = 'uJy'
                            newhdu.header.add_comment(f'Flux per pixel in uJy, calculated from the observed data and pixel solid angle {omega_pix_obs.to_value(u.sr)} sr')
                            obs_hdul.append(newhdu)

                            newhdu = apfits.ImageHDU(data=sim_obs_binned, name="MODEL_FLUX")
                            newhdu.header['BUNIT'] = 'uJy' 
                            newhdu.header['TI'] = inertia
                            newhdu.header.add_comment(f'Black body flux from TI={inertia} model temperatures, convolved with PSF and binned to match observation')
                            newhdu.header.add_comment(f'uJy/pixel')
                            obs_hdul.append(newhdu)

                            cols = [
                                apfits.Column(name='WAVELENGTH',   format='D', unit=str(waves.unit), array=waves.value), 
                                apfits.Column(name='RADIUS',   format='D', unit='pixels', array=flux_rads),
                            ]
                            newhdu = apfits.BinTableHDU.from_columns(cols, name='RADII') 
                            newhdu.header['TI'] = inertia
                            newhdu.header['FLUXFRAC'] = 0.95
                            newhdu.header['X0'] = body.get_x0()
                            newhdu.header['Y0'] = body.get_y0()
                            newhdu.header['R0'] = body.get_r0()
                            newhdu.header.add_comment(f'Radius at which 95% of the model flux is captured for each wavelength')
                            obs_hdul.append(newhdu)

                            cols = [apfits.Column(name='RADIUS_ARRAY',   format='D', unit='pixels', array=radius_array),
                                    apfits.Column(name='FLUX_FRAC', format=f'{flux_fracs.shape[0]}D', unit='fraction', array=flux_fracs, dim=f'({flux_fracs.shape[1]})')]
                            newhdu = apfits.BinTableHDU.from_columns(cols, name='FLUX_FRACTIONS')
                            newhdu.header['TI'] = inertia
                            newhdu.header.add_comment(f'Flux fractions vs radius for each wavelength, where radius is in pixels.')
                            obs_hdul.append(newhdu)

                            obs_hdul.writeto(f"{savedir}/Level3_ch{ch}-{band.lower()}_s3d_psf.fits", overwrite=True)

                            ### Plot simulated observation and actual observations ###
                            fig, ax = plt.subplots(3,4, figsize=(22,18))
                            fig.suptitle(f'{thermal_info['target']} {hem}ing {dith.upper()} channel {ch} - {band}', fontsize=20)
                            for pi,i in enumerate([len(waves)//4, len(waves)//2, 3*(len(waves)//4)]):
                                # plot offset to avoid issues with log scaling
                                obs_data = (body.data[i]*(u.MJy/u.sr)*omega_pix_obs).to(u.uJy).value # convert MJy/sr to uJy/pixel
                                # obs_data = body.data[i] # default units are surface brightness: MJy/sr
                                offset = np.abs(np.nanmin(obs_data))

                                tmbody.plot_wireframe_radec(ax[pi][0])
                                p1  = ax[pi][0].pcolormesh(
                                            tmbody.get_ra_img().T,
                                            tmbody.get_dec_img().T,
                                            model_temps,
                                            cmap='rainbow')
                                plt.colorbar(p1, ax=ax[pi][0])
                                ax[pi][0].set_title(f'Temperature Model TI={inertia}', fontsize=14)

                                tmbody.plot_wireframe_radec(ax[pi][1])
                                p2 = ax[pi][1].pcolormesh(
                                        tmbody.get_ra_img().T,
                                        tmbody.get_dec_img().T,
                                        sim_obs_cube[i]+offset,
                                        cmap='rainbow', norm = LogNorm(max(.1+offset,np.nanpercentile(sim_obs_cube[i]+offset,1)), np.nanpercentile(sim_obs_cube[i]+offset,99))) #np.nanpercentile(sim_obs_cube[i]),50)
                                plt.colorbar(p2, ax=ax[pi][1])
                                ax[pi][1].set_title(f'Simulated Observation at {np.round(waves[i],3)}', fontsize=14)

                                body.plot_wireframe_radec(ax[pi][2])
                                p3 = ax[pi][2].pcolormesh(
                                        body.get_ra_img(),
                                        body.get_dec_img(),
                                        sim_obs_binned[i]+offset,
                                        cmap='rainbow', norm = LogNorm(max(0.1+offset,np.nanpercentile(sim_obs_binned[i]+offset,1)), np.nanpercentile(sim_obs_binned[i]+offset,99))) #np.nanpercentile(sim_obs_binned[i],50)
                                
                                ax[pi][2].set_title(f'Binned Simulation at {np.round(waves[i],3)}', fontsize=14)
                                plt.colorbar(p3, ax=ax[pi][2])

                                # Real observation for comparison:
                                body.plot_wireframe_radec(ax[pi][3])
                                p4 = ax[pi][3].pcolormesh(
                                        body.get_ra_img(),
                                        body.get_dec_img(),
                                        obs_data+offset,
                                        cmap='rainbow', norm = LogNorm(np.nanpercentile(obs_data+offset,5), np.nanpercentile(obs_data,99)))
                                ax[pi][3].set_title(f'Actual Observation at {np.round(waves[i],3)}', fontsize=14)
                                plt.colorbar(p4, ax=ax[pi][3])
                            plt.tight_layout(rect=[0, 0, 1, 0.98])
                            plt.savefig(f"{savedir}/plots/Level3_ch{ch}-{band.lower()}_TI_{inertia}_simulated_obs.png", dpi=300);  
                            plt.close() 
                            # Update progress bar
                        pbar.update(1) 

def run_custom_tmpsf(datapath, path_pattern, thermal_info, psf_kernel_path):
    """ Run the full custom PSF generation process:
        1. Generate oversampled thermal models
        2. Convolve with PSF and save simulated observations 
        
    Parameters:     
        -----------             
        datapath : dict
        Dictionary with keys for hemisphere e.g. 'lead' and 'trail' pointing to data directories
        path_pattern : str ('bg_fringe_fringe1d')
            Pattern for data directories produced by jwstGiantPlanets pipeline
        thermal_info: dict
            Dictionary with keys:
                'obskey_prefix': str, prefix for observation keys (e.g. 'g' for Ganymede)
                'target': str, target name for thermal models (e.g. 'Callisto')
                'inertias': list of int, thermal inertia values to process
        psf_kernel_path: str: path to pickled stpsfs dictionary with PSF kernels
        """
    
    # Crop observations and generate oversampled thermal models
    generate_thermal_models(datapath, path_pattern=path_pattern, thermal_info=thermal_info)

    print('Thermal models generated. Now convolving with PSF and saving simulated observations...')
    generate_thermal_psf_models(datapath, path_pattern=path_pattern,
                                thermal_info=thermal_info, psf_kernel_path=psf_kernel_path)
    




#if __name__ == "__main__":
    # Sample usage
    # datapath = {'lead': "/home/rdavis/DataAnalysis/data/jwst/miri/callisto/reduced/leading70W/stage3_desaturated",
    #             'trail': "/home/rdavis/DataAnalysis/data/jwst/miri/callisto/reduced/trailing240W/stage3_desaturated"}
    # thermal_info = {'obskey_prefix': '', # for thermal model files
    #                 'target': 'Callisto',
    #                 'inertias': [10, 30, 50, 100, 200]  # Thermal inertias used in the thermal model
    #                 }
    # psf_kernel_path = f"/home/rdavis/DataAnalysis/pipelines/MIRISatellites/jwstGiantPlanets/miri_psf_kernels.pkl"
    # path_pattern = 'bg_fringe_fringe1d' # pattern for data directories produced by jwstGiantPlanets pipeline

    # run_custom_tmpsf(datapath, path_pattern, thermal_info, psf_kernel_path)
    
    
    


